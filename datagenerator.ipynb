{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 13:21:36.013449: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 13:21:36.565892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from libs.location import *\n",
    "import shutil\n",
    "\n",
    "dataset_dir = CLASSIFIED_TRAINING_IMG_JPG_LOCATION_PATH\n",
    "output_dir = BALANCED_TRAINING_IMG_JPG_LOCATION_PATH\n",
    "\n",
    "target_class_balance = 1.0\n",
    "target_num_samples = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    num_samples = len(os.listdir(class_dir))\n",
    "    target_num_samples[class_name] = num_samples\n",
    "\n",
    "# Find the class with fewer samples (minority class)\n",
    "majority_class = max(target_num_samples, key=target_num_samples.get)\n",
    "minority_class = min(target_num_samples, key=target_num_samples.get)\n",
    "\n",
    "no_of_majority_samples = target_num_samples[majority_class]\n",
    "\n",
    "class_name = minority_class\n",
    "class_dir = os.path.join(dataset_dir, class_name)\n",
    "num_original_samples = len(os.listdir(class_dir))\n",
    "num_samples_needed = no_of_majority_samples\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    brightness_range=[-1, 1],\n",
    ")\n",
    "output_class_dir = os.path.join(output_dir, class_name)\n",
    "os.makedirs(output_class_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting images for class: class-1\n",
      "Found 6012 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Augmenting images for class: {class_name}\")\n",
    "class_datagen = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    save_to_dir=None,\n",
    "    save_format=\"jpg\",\n",
    "    save_prefix=f\"{class_name}_augmented\",\n",
    "    classes=[class_name],  # Specify the class name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20672"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples_needed // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_datagen.next()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = class_datagen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 224, 224, 3), (32, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape,batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class-1/class-1_000db696-cf54-4385-b10b-6b16fbb3f985.jpg'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_datagen.filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_samples_needed // 32):\n",
    "    batch = class_datagen.next()\n",
    "    for j, image_array in enumerate(batch):\n",
    "        original_name = class_datagen.filenames[j].split(os.path.sep)[-1]\n",
    "        image_path = os.path.join(class_dir, original_name)\n",
    "        new_image_path = os.path.join(output_class_dir, original_name)\n",
    "        shutil.copy(image_path, new_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
